{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAT网络\n",
    "参考链接  \n",
    "1.[Graph Attention Networks (GAT)](https://nn.labml.ai/graphs/gat/index.html)  \n",
    "2. [图注意网络GAT理解及Pytorch代码实现【PyGAT代码详细注释】](https://blog.csdn.net/weixin_43629813/article/details/129278266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from labml_helpers.module import Module\n",
    "\n",
    "\n",
    "class GraphAttentionLayer(Module):\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, n_heads: int,\n",
    "                is_concat: bool = True,\n",
    "                dropout: float = 0.6,\n",
    "                leaky_relu_negative_slope: float = 0.2):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.is_concat = is_concat\n",
    "        self.n_heads = n_heads\n",
    "\n",
    "        # Calculate the number of dimensions per head\n",
    "        if is_concat:\n",
    "            assert out_features % n_heads == 0\n",
    "            # If we are concatenating the multiple heads\n",
    "            self.n_hidden = out_features // n_heads\n",
    "        else:\n",
    "            # If we are averaging the multiple heads\n",
    "            self.n_hidden = out_features\n",
    "\n",
    "        # Linear layer for initial transformation;\n",
    "        # i.e. to transform the node embeddings before self-attention\n",
    "        self.linear = nn.Linear(in_features, self.n_hidden * n_heads, bias=False)\n",
    "        # Linear layer to compute attention score $e_{ij}$\n",
    "        self.attn = nn.Linear(self.n_hidden * 2, 1, bias=False)\n",
    "        # The activation for attention score $e_{ij}$\n",
    "        self.activation = nn.LeakyReLU(negative_slope=leaky_relu_negative_slope)\n",
    "        # Softmax to compute attention $\\alpha_{ij}$\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        # Dropout layer to be applied for attention\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, h: torch.Tensor, adj_mat: torch.Tensor):\n",
    "\n",
    "\n",
    "        n_nodes = h.shape[0]\n",
    "\n",
    "        g = self.linear(h).view(n_nodes, self.n_heads, self.n_hidden)\n",
    "\n",
    "        g_repeat = g.repeat(n_nodes, 1, 1)\n",
    "\n",
    "        g_repeat_interleave = g.repeat_interleave(n_nodes, dim=0)\n",
    "\n",
    "        g_concat = torch.cat([g_repeat_interleave, g_repeat], dim=-1)\n",
    "        # Reshape so that `g_concat[i, j]` is $\\overrightarrow{g_i} \\Vert \\overrightarrow{g_j}$\n",
    "        g_concat = g_concat.view(n_nodes, n_nodes, self.n_heads, 2 * self.n_hidden)\n",
    "\n",
    "        e = self.activation(self.attn(g_concat))\n",
    "        # Remove the last dimension of size `1`\n",
    "        e = e.squeeze(-1)\n",
    "\n",
    "        # The adjacency matrix should have shape\n",
    "        # `[n_nodes, n_nodes, n_heads]` or`[n_nodes, n_nodes, 1]`\n",
    "        assert adj_mat.shape[0] == 1 or adj_mat.shape[0] == n_nodes\n",
    "        assert adj_mat.shape[1] == 1 or adj_mat.shape[1] == n_nodes\n",
    "        assert adj_mat.shape[2] == 1 or adj_mat.shape[2] == self.n_heads\n",
    "        # Mask $e_{ij}$ based on adjacency matrix.\n",
    "        # $e_{ij}$ is set to $- \\infty$ if there is no edge from $i$ to $j$.\n",
    "        e = e.masked_fill(adj_mat == 0, float('-inf'))\n",
    "\n",
    "        a = self.softmax(e)\n",
    "\n",
    "        # Apply dropout regularization\n",
    "        a = self.dropout(a)\n",
    "\n",
    "        attn_res = torch.einsum('ijh,jhf->ihf', a, g)\n",
    "\n",
    "        # Concatenate the heads\n",
    "        if self.is_concat:\n",
    "            # $$\\overrightarrow{h'_i} = \\Bigg\\Vert_{k=1}^{K} \\overrightarrow{h'^k_i}$$\n",
    "            return attn_res.reshape(n_nodes, self.n_heads * self.n_hidden)\n",
    "        # Take the mean of the heads\n",
    "        else:\n",
    "            # $$\\overrightarrow{h'_i} = \\frac{1}{K} \\sum_{k=1}^{K} \\overrightarrow{h'^k_i}$$\n",
    "            return attn_res.mean(dim=1)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "# Create an instance of the GAT model\n",
    "default_gat = GraphAttentionLayer(in_features=512, out_features=256, n_heads=1)\n",
    "time_gat = GraphAttentionLayer(in_features=512, out_features=256, n_heads=1)\n",
    "star_gat = GraphAttentionLayer(in_features=512, out_features=256, n_heads=1)\n",
    "\n",
    "\n",
    "# Create some sample input tensors\n",
    "# Node embeddings\n",
    "default_h = torch.randn(5, 512)  \n",
    "time_h = torch.randn(7, 512)  \n",
    "star_h = torch.randn(3, 512)  \n",
    "# Adjacency matrix\n",
    "default_adj = torch.ones(5, 5, 1)\n",
    "time_adj = torch.ones(7, 7, 1)\n",
    "star_adj = torch.ones(3, 3, 1)\n",
    "# Target node index\n",
    "default_index: int = default_adj.shape[0]//2 \n",
    "time_index: int = time_adj.shape[0]//2 \n",
    "star_index: int = star_adj.shape[0]//2\n",
    "\n",
    "# Forward pass through the GAT model\n",
    "node_default = default_gat(default_h, default_adj)[default_index]\n",
    "node_time = time_gat(time_h, time_adj)[time_index]  \n",
    "node_star = star_gat(star_h, star_adj)[star_index]\n",
    "node_all = 0.5*node_default + 0.25*node_time + 0.25*node_star\n",
    "\n",
    "# Print the output\n",
    "print(node_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(enumerate(self._trainloader), total=num_batch, disable=not self._verbose) as pbar:\n",
    "    for step, (inputs, target) in pbar:\n",
    "        rvw_batch_id = inputs['id_right']\n",
    "        unique_items = set(rvw_batch_id)\n",
    "        batch_x = {}\n",
    "        nbrs = {}\n",
    "        for key, value in inputs.items():\n",
    "            if key in (\"id_left\", \"id_right\"):\n",
    "                batch_x[key] = value\n",
    "                continue\n",
    "            elif key in (\"text_left\", \"text_left_length\", \"image_left\", \"image_left_length\"):\n",
    "                batch_x[key] = value.cuda(0)\n",
    "                continue\n",
    "            elif key == \"text_right\":\n",
    "                batch_x[key] = []\n",
    "                for d in value:\n",
    "                    ke, val = next(iter(d.items()))\n",
    "                    batch_x[key].append(val)\n",
    "                batch_x[key] = torch.tensor(batch_x[key]).cuda(0)\n",
    "\n",
    "                for i, d in enumerate(value):\n",
    "                    # 创建一个新的nbr字典\n",
    "                    nbr = {'id': [], 'text': [], 'text_length': [], 'image': [], 'image_length': []}\n",
    "                    # 提取每个字典的第一个键值对\n",
    "                    first_key, first_val = next(iter(d.items()))\n",
    "                    if first_key not in unique_items:\n",
    "                        continue\n",
    "                    # 提取每个字典的其他键值对\n",
    "                    for key, val in list(d.items())[1:]:\n",
    "                        nbr['id'].append(key)\n",
    "                        nbr['text'].append(val)\n",
    "                    # 将第一个键值对添加到'id'和'text'的最后\n",
    "                    nbr['id'].append(first_key)\n",
    "                    nbr['text'].append(first_val)\n",
    "                    nbr['text'] = torch.tensor(nbr['text']).cuda(0)\n",
    "                    # 将每个字典形成的nbr放进大字典nbrs中\n",
    "                    nbrs[first_key] = nbr\n",
    "                    unique_items.remove(first_key)\n",
    "            elif key == \"image_right_length\":\n",
    "                batch_x[key] = []\n",
    "                for d in value:\n",
    "                    ke, val = next(iter(d.items()))\n",
    "                    batch_x[key].append(val[0])\n",
    "                batch_x[key] = torch.tensor(batch_x[key]).cuda(0)\n",
    "                unique_items = list(nbrs.keys())\n",
    "\n",
    "                for dict in value:\n",
    "                    # 使用字典的键访问其值（列表）\n",
    "                    for ket, val in dict.items():\n",
    "                        if ket not in unique_items:\n",
    "                            continue\n",
    "                        val.append(val[0])  # 将第一个元素添加到列表末尾\n",
    "                        del val[0]\n",
    "                        nbrs[ket]['image_length'].extend(val)\n",
    "                        unique_items.remove(ket)\n",
    "                        nbrs[ket]['image_length'] = torch.tensor(nbrs[ket]['image_length']).cuda(0)\n",
    "            elif key == \"image_right\":\n",
    "                batch_x[key] = []\n",
    "                for d in value:\n",
    "                    ke, val = next(iter(d.items()))\n",
    "                    batch_x[key].append(val[0])\n",
    "                batch_x[key] = torch.tensor(batch_x[key]).cuda(0)\n",
    "                unique_items = list(nbrs.keys())\n",
    "\n",
    "                for dict in value:\n",
    "                    # 使用字典的键访问其值（列表）\n",
    "                    for ket, val in dict.items():\n",
    "                        if ket not in unique_items:\n",
    "                            continue\n",
    "                        val.append(val[0])  # 将第一个元素添加到列表末尾\n",
    "                        del val[0]\n",
    "                        nbrs[ket]['image'].extend(val)\n",
    "                        unique_items.remove(ket)\n",
    "                        nbrs[ket]['image'] = torch.tensor(nbrs[ket]['image']).cuda(0)\n",
    "            elif key == \"text_right_length\":\n",
    "                unique_items = list(nbrs.keys())\n",
    "                batch_x[key] = []\n",
    "                for d in value:\n",
    "                    ke, val = next(iter(d.items()))\n",
    "                    batch_x[key].append(val)\n",
    "                batch_x[key] = torch.tensor(batch_x[key]).cuda(0)\n",
    "                for item in value:\n",
    "                    ket = list(item.keys())[0]  # 提取每个字典的第一个键\n",
    "                    if ket not in unique_items:  # 如果这个键在unique_items中\n",
    "                        continue\n",
    "                    val = list(item.values())  # 将字典的键对应的值提取出来形成一个列表val\n",
    "                    val.append(val[0])  # 将第一个元素添加到列表末尾\n",
    "                    del val[0]\n",
    "                    # nbr = {'id': [], 'text': [], 'text_length': [], 'image': [], 'image_length': []}\n",
    "                    nbrs[ket]['text_length'].extend(val)\n",
    "                    unique_items.remove(ket)\n",
    "                    nbrs[ket]['text_length'] = torch.tensor(nbrs[ket]['text_length']).cuda(0)\n",
    "\n",
    "        inputs = batch_x\n",
    "        inputs['time_nbr'] = nbrs\n",
    "        target = target.cuda(0)\n",
    "        outputs = self._model(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
